import imblearn
from sklearn.ensemble import RandomForestClassifier
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import TomekLinks
from imblearn.over_sampling import SMOTE
import sklearn

from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split, GridSearchCV
import pandas as pd
from xgboost import XGBClassifier
import sys

remote_path = "results-undersampling.txt"

with open(remote_path, "w") as f:
    sys.stdout = f  # Redirect output to the file

    data = pd.read_csv('train_test_dataset.csv')
    df = pd.DataFrame(data)

    # Calculating the ratio of benign to malware APKs
    malware_column = df['Malware']
    ratio_ones_to_zeroes = malware_column.value_counts(normalize=True)
    print("Ratio of Benign APKs to Malware APKs:")
    print(ratio_ones_to_zeroes)

    # Set display options
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    df = df.drop(['APK Name'], axis=1)

    # Print the names of all columns
    column_names = df.columns
    column_names_list = column_names.to_list()

    for col in column_names_list:
        df[col] = df[col].astype(int)

    # Split data into features and target
    X = df.drop(columns=['Malware'])  # Dropping the target
    y = df['Malware']

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)

    # Check the proportions in the training and testing sets
    print("Proportion of Malware in Training Set:")
    print(y_train.value_counts(normalize=True))
    print("Proportion of Malware in Testing Set:")
    print(y_test.value_counts(normalize=True))

    # Sampling procedures
    sampling_techniques = {
        "Random Under-sampling": RandomUnderSampler(random_state=42, replacement=True),
        # "Random Over-sampling": RandomOverSampler(random_state=42),
        "Tomek Links": TomekLinks(sampling_strategy='majority')
        # "SMOTE": SMOTE()
    }


    rf_model = RandomForestClassifier()
    xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

    # Parameter Grid for Random Forest
    param_grid_rf = {
        'n_estimators': [50, 100, 200, 500, 1000],
        'max_depth': [None, 10, 16, 20, 30, 40],
        'min_samples_split': [2, 5, 10, 20, 50]
    }
    # Define the parameter grid for XGBoost
    param_grid_xgb = {
        'n_estimators': [50, 100, 200, 500],
        'max_depth': [3, 6, 9, 12],
        'learning_rate': [0.001, 0.01, 0.1, 0.3],
        'subsample': [0.5, 0.8, 1.0],
        'colsample_bytree': [0.5, 0.8, 1.0]
    }

    print(f"=================RF RESULTS===================")
    for technique_name, sampler in sampling_techniques.items():
    
        # Apply the sampling technique to the training set
        X_train_sampled, y_train_sampled = sampler.fit_resample(X_train, y_train)

        grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=10, verbose=2, n_jobs=-1)

        # Fit the model with the sampled training data
        grid_search_rf.fit(X_train_sampled, y_train_sampled)

        # Predict and evaluate using the best model
        best_rf = grid_search_rf.best_estimator_
        y_pred_rf = best_rf.predict(X_test)

        print(f"================={technique_name} RESULTS===================")
        print("Best Parameters: ", grid_search_rf.best_params_)
        print("Accuracy:", accuracy_score(y_test, y_pred_rf))

        # Additional metrics
        print("Precision (Malware):", precision_score(y_test, y_pred_rf, pos_label=1))
        print("Recall (Malware):", recall_score(y_test, y_pred_rf, pos_label=1))
        print("F1 Score (Malware):", f1_score(y_test, y_pred_rf, pos_label=1))

        # Classification report
        print(classification_report(y_test, y_pred_rf, labels=[0, 1], target_names=["Benign", "Malware"]))
        
    print(f"=================XGBoost RESULTS===================")
    for technique_name, sampler in sampling_techniques.items():
    
        # Apply the sampling technique to the training set
        X_train_sampled, y_train_sampled = sampler.fit_resample(X_train, y_train)

        grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=10, verbose=2, n_jobs=-1)

        # Fit the model with the sampled training data
        grid_search_xgb.fit(X_train_sampled, y_train_sampled)

        # Predict and evaluate using the best model
        best_xgb = grid_search_xgb.best_estimator_
        y_pred_xgb = best_xgb.predict(X_test)

        print(f"================={technique_name} RESULTS===================")
        print("Best Parameters: ", grid_search_xgb.best_params_)
        print("Accuracy:", accuracy_score(y_test, y_pred_xgb))

        # Additional metrics
        print("Precision (Malware):", precision_score(y_test, y_pred_xgb, pos_label=1))
        print("Recall (Malware):", recall_score(y_test, y_pred_xgb, pos_label=1))
        print("F1 Score (Malware):", f1_score(y_test, y_pred_xgb, pos_label=1))

        # Classification report
        print(classification_report(y_test, y_pred_xgb, labels=[0, 1], target_names=["Benign", "Malware"]))

# Reset the output to the console
sys.stdout = sys.__stdout__

print("Results have been written to 'results-undersampling.txt'")
